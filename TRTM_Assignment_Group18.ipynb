{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mXjosWrhqd0"
      },
      "source": [
        "# Text Retrieval and Mining - BSc BAN Y3 - Assignment\n",
        "\n",
        "* BSc Business Analytics\n",
        "* Faculty of Economics and Business\n",
        "* University of Amsterdam\n",
        "* Authors: Claudia Orellana Rodriguez, [Julien Rossi](mailto://j.rossi@uva.nl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HNQ0FG8ybFK"
      },
      "source": [
        "# Student Group\n",
        "\n",
        "* Student 1\n",
        "* Student 2\n",
        "* Student 3\n",
        "* Student 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGK__XQfGYVv"
      },
      "source": [
        "# Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8wD6iFIGcX_"
      },
      "source": [
        "* This assignment is a group assignment\n",
        "* Submit this notebook through Canvas\n",
        "* The assignment is made of 3 questions\n",
        "* The assignment includes an oral presentation in which you will describe your work and justify your answers\n",
        "* For the coding in the assignment you are free to re-use all the course material\n",
        "  * Lecture notebooks\n",
        "  * Tutorial notebooks\n",
        "\n",
        "___\n",
        "\n",
        "\n",
        "**GRADING**\n",
        "* Question 1: 5 points\n",
        "* Question 2: 10 points\n",
        "* Question 3: 5 points\n",
        "* Presentation: 5 points\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeWqYisHDQiE"
      },
      "source": [
        "**GPU WARNING**\n",
        "* We will use transformers\n",
        "* It is best to use a GPU-based runtime on Google Colab (this notebook has the good runtime)\n",
        "* With a powerful laptop you could achieve the same result, be careful with overheating during the encoding phase (Question 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swN30bDQ5iC4"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-ldMMp0-KSw"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "logger = logging.getLogger(\"TRTM\")\n",
        "logger.setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rGAv1Xo5B0Q"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "r = requests.get(\"https://raw.githubusercontent.com/j-rossi-nl/teaching-data/main/2024_TRTM/climate_flying_text.zip\")\n",
        "assert r.status_code == 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkIeaFl-6Bha"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "from zipfile import ZipInfo\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "datafile_re = re.compile(r\"^climate_flying_text/stayingOnTheGround_(?P<theme>[^_\\.]+)(_text)?\\.csv$\")\n",
        "dfs: list[pd.DataFrame] = []\n",
        "\n",
        "with ZipFile(BytesIO(r.content), mode=\"r\") as zf:\n",
        "    info: ZipInfo\n",
        "    for info in zf.filelist:\n",
        "        if info.is_dir():\n",
        "            continue\n",
        "\n",
        "        m = datafile_re.match(info.filename)\n",
        "        if m is None:\n",
        "            logger.warning(f\"Skipping {info.filename}\")\n",
        "            continue\n",
        "\n",
        "        logger.info(f\"Loading data from {info.filename}\")\n",
        "        with zf.open(info, mode=\"r\") as datafile:\n",
        "            df = pd.read_csv(datafile)\n",
        "        df[\"theme\"] = m.group(\"theme\")\n",
        "        dfs.append(df)\n",
        "\n",
        "flying = pd.concat(dfs).drop(columns=[\"id\"]).dropna(subset=[\"text\"]).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYqI4cQmBhAW"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0n-kKHqEfsx"
      },
      "outputs": [],
      "source": [
        "r = requests.get(\"https://surfdrive.surf.nl/files/index.php/s/Z32zhlJz5iuHEGu/download\")\n",
        "assert r.status_code == 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLultBIVQJXA"
      },
      "outputs": [],
      "source": [
        "from spacy.tokens import DocBin\n",
        "docbin = DocBin().from_bytes(r.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NCX5Er-Pezg"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "flying[\"spacy\"] = list(docbin.get_docs(vocab=nlp.vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS1yaiUK61fJ"
      },
      "outputs": [],
      "source": [
        "flying.shape   # should be (129091, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nm2VjYNLgq5i"
      },
      "outputs": [],
      "source": [
        "flying.drop_duplicates(subset=[\"text\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3XA3yNJhEl0"
      },
      "outputs": [],
      "source": [
        "flying.shape  # should be (40695, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urNQynwsBYiB"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "px.histogram(\n",
        "    data_frame=flying,\n",
        "    x=\"theme\",\n",
        "    color=\"theme\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lljslM0PG-Va"
      },
      "source": [
        "# Data Description\n",
        "\n",
        "You are working with a dataset of tweets collected under the umbrella \"Staying on the ground\", in reference to a swedish campaign [\"Stay on the ground\"](https://westayontheground.org/), against the continued growth of the aviation sector, in light of climate change.\n",
        "\n",
        "This dataset is articulated around themes:\n",
        "* `\"equity\"`: how are the changes equitable for everyone ?\n",
        "* `\"policySupportingAviationReduction\"` and `\"policySupportingAviationReduction2\"`: about public policies that would reduce the aviation industry\n",
        "* `\"ccConsequences\"`: about the consequences of climate change\n",
        "* `\"flightShame\"`: shaming those who decide to fly\n",
        "* `\"alternatives`\": better travel choices than flying\n",
        "* `\"practicingChange`\": examples of people's practices\n",
        "\n",
        "___\n",
        "\n",
        "\n",
        "The dataframe `flying` has 3 columns:\n",
        "* `text`: the original message\n",
        "* `theme`: the theme of the message\n",
        "* `spacy`: a `Doc` object from `spacy` corresponding to the message\n",
        "\n",
        "___\n",
        "\n",
        "\n",
        "In this assignment, you will study different facets of the dataset while practicing the following class material:\n",
        "* Entities, POS tagging\n",
        "* Topic Modeling\n",
        "* Text Representation and Clustering\n",
        "\n",
        "You do not need to process the dataset yourself with `SpaCy`, this is already done."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUEo7di0Pacz"
      },
      "source": [
        "# Question 1 - Entities\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2H0vg7oPdGo"
      },
      "source": [
        "**ASSIGNMENT**\n",
        "* What are the TOP-3 most popular entity categories by number of mentions ?\n",
        "* Who are the TOP-10 most popular persons ?\n",
        "* Who are the TOP-10 most mentioned locations / geo-political entities ?\n",
        "* What are the TOP-10 entity categories by number of mentions containing `\"greta\"`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GO7iZmtBLMg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_X4R8leeBLJO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWceOZEBBLGd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4tnFX0XBLDn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3ZkLZURBLAo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tf4N8Qi_BK9_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JThK2x8-BK7J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T35zJ93OBK4E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaHHRXXBBK1H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXj5TvOSBKx9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4Vvc3wMBKu9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EnBJVyBtPaI"
      },
      "source": [
        "# Question 2 - Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyOMUW5nqgGt"
      },
      "source": [
        "We focus on the theme `\"alternatives\"`. Within this theme we want to cluster the messages, in a way similar to the topic modeling, without using LDA or BERTopic.\n",
        "\n",
        "* The `\"alternatives\"` theme is made of 4913 messages\n",
        "* We will create document embeddings\n",
        "* Then cluster these embeddings using K-Means\n",
        "* Then represent our clustering on a 2D scatter plot, which will require a dimensionality reduction\n",
        "\n",
        "___\n",
        "\n",
        "\n",
        "**DOCUMENT EMBEDDINGS**\n",
        "* We will use [Sentence Transformers](https://huggingface.co/sentence-transformers) from huggingface\n",
        "* The model is `\"paraphrase-distilroberta-base-v1\"`\n",
        "* Instantiate the model\n",
        "* Use it for encoding the messages\n",
        "* The result is a `numpy.array` with shape `(4913, d)` where `d` is the number of dimensions of the document embeddings\n",
        "\n",
        "___\n",
        "\n",
        "\n",
        "**K-Means**\n",
        "* Use [SKLearn KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n",
        "* Use the elbow method\n",
        "* Plot the inertia of each clustering model for a number of clusters from 1 to 20\n",
        "\n",
        "___\n",
        "\n",
        "\n",
        "**DIMENSIONALITY REDUCTION**\n",
        "* We will use [UMAP](https://umap-learn.readthedocs.io/en/latest/basic_usage.html)\n",
        "* Create a 2-D representation of the document embeddings\n",
        "* Plot this 2-D representation as a scatter plot\n",
        "* Each document is one dot, with a color representing the cluster it has been allocated to\n",
        "\n",
        "___\n",
        "\n",
        "\n",
        "**CLUSTERING ANALYSIS**\n",
        "* Select 2 clusters\n",
        "* Show for each cluster the 10 documents which have the embeddings the closest to the cluster centroid\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyHY2TSgiU7p"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers umap-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQYtOOrABQEs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3UrydX2BQB2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yS7TaIBeBP-4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AOsTjO8BP7-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_dd_MMOBP5E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-Fellt6BP2O"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVDjMAVwBPzU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKarDt-7BPwX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2LFGoYtBPte"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_ofpOFFBPqx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chK8-JoPBPn5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoJByo39BPkx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpFnSR06BPh0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzgMfCT_BPez"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IUKzcEwxVwW"
      },
      "source": [
        "# Question 3 - LDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvZBny97BTaB"
      },
      "source": [
        "* Use the complete corpus\n",
        "* We will tokenize the corpus\n",
        "* Create a LDA model with 8 topics\n",
        "\n",
        "___\n",
        "\n",
        "\n",
        "**TOKENIZATION**\n",
        "* Consider the lowercased corpus\n",
        "* Use the `TweetTokenizer` from NLTK\n",
        "* For tokenization, consider the following:\n",
        "  * Remove the english stopwords (from the NLTK list of stopwords)\n",
        "  * Consider `\"rt\"` as a stopword\n",
        "  * Keep only the tokens made of letters only, at least 3 letters\n",
        "* Create a `gensim` Dictionary\n",
        "  * Filter out tokens that appear in less than 5 documents\n",
        "  * Filter out tokens that appear in more than 90% of the documents\n",
        "\n",
        "\n",
        "___\n",
        "\n",
        "\n",
        "**LDA**\n",
        "* Create a LDAModel from gensim\n",
        "* With 8 topics\n",
        "* Display the word clouds corresponding to the Top-10 words in each topic\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkX4giqxBSpH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUU2STIsBSma"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAZQRv1OBSji"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVmXKA0_BSgs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtjdsx5NBSd2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAQuSXoDBSa8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xyhasg3rBSXu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z95v0xVfBSU6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
